{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date      Close       High        Low       Open     Volume\n",
      "0 2012-05-18  38.050671  44.788914  37.821750  41.852752  573576400\n",
      "1 2012-05-21  33.870369  36.488033  32.845202  36.358642  168192700\n",
      "2 2012-05-22  30.854582  33.432433  30.794864  32.457030  101786600\n",
      "3 2012-05-23  31.849894  32.347548  31.212896  31.222850   73600000\n",
      "4 2012-05-24  32.875061  33.054217  31.620973  32.795438   50237200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "df = yf.download('META', start = '2010-01-01', end = '2024-01-01').reset_index()\n",
    "df.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Close\n",
      "0  38.050671\n",
      "1  33.870369\n",
      "2  30.854582\n",
      "3  31.849894\n",
      "4  32.875061\n",
      "       Close  Prediction\n",
      "0  38.050671   19.547871\n",
      "1  33.870369   19.657354\n",
      "2  30.854582   19.428436\n",
      "3  31.849894   19.428436\n",
      "4  32.875061   19.388620\n"
     ]
    }
   ],
   "source": [
    "df = df[['Close']]\n",
    "print(df.head())\n",
    "# A vairable for predicting 'x' days out into the future\n",
    "future_day = 100\n",
    "\n",
    "# Create another column (target for dependent variable) shifted 'x' unit up\n",
    "df['Prediction'] = df[['Close']].shift(-future_day)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 38.05067062]\n",
      " [ 33.87036896]\n",
      " [ 30.85458183]\n",
      " ...\n",
      " [309.2723999 ]\n",
      " [315.07504272]\n",
      " [311.17346191]]\n",
      "[[19.54787064]\n",
      " [19.65735435]\n",
      " [19.42843628]\n",
      " ...\n",
      " [        nan]\n",
      " [        nan]\n",
      " [        nan]]\n",
      "[[ 19.54787064]\n",
      " [ 19.65735435]\n",
      " [ 19.42843628]\n",
      " ...\n",
      " [356.15145874]\n",
      " [356.63919067]\n",
      " [352.29959106]]\n"
     ]
    }
   ],
   "source": [
    "# Create the independent data set X\n",
    "# convert the dataframe to a numpy array\n",
    "X = np.array(df.drop(['Prediction'], axis=1))\n",
    "# remove the last few rows\n",
    "X = X[:-future_day]\n",
    "print(X)\n",
    "\n",
    "# Create the dependent data set y\n",
    "# Convert the dataframe to a numpy array(including the Nan)\n",
    "y = np.array(df.drop(['Close'], axis=1))\n",
    "print(y)\n",
    "# Get all of the y values except the last x rows\n",
    "y = y[:-future_day]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data 80/20\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,train_size=0.8, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1)\n",
      "{'C': 1, 'kernel': 'rbf'}\n",
      "0.7744334702078793\n",
      "0.7990393348106678\n",
      "{'mean_fit_time': array([0.07177   , 0.04397163, 0.04401937, 0.20447474, 0.05119858,\n",
      "       0.04344006, 1.3057426 , 0.07395597, 0.04205661]), 'std_fit_time': array([0.00382882, 0.00079516, 0.00037227, 0.01700184, 0.00525086,\n",
      "       0.00033899, 0.08474279, 0.00436401, 0.00024629]), 'mean_score_time': array([0.00640244, 0.00501103, 0.01864424, 0.0062119 , 0.00495596,\n",
      "       0.01846051, 0.00632734, 0.00517521, 0.01834507]), 'std_score_time': array([1.94001618e-04, 1.46433066e-04, 3.49798379e-04, 1.42864630e-04,\n",
      "       7.49443916e-05, 4.19709103e-04, 1.82894583e-04, 9.71993219e-05,\n",
      "       3.09531098e-04]), 'param_C': masked_array(data=[0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 1.0, 1.0, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=1e+20), 'param_kernel': masked_array(data=['linear', 'poly', 'rbf', 'linear', 'poly', 'rbf',\n",
      "                   'linear', 'poly', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=np.str_('?'),\n",
      "            dtype=object), 'params': [{'C': 0.01, 'kernel': 'linear'}, {'C': 0.01, 'kernel': 'poly'}, {'C': 0.01, 'kernel': 'rbf'}, {'C': 0.1, 'kernel': 'linear'}, {'C': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'kernel': 'rbf'}, {'C': 1, 'kernel': 'linear'}, {'C': 1, 'kernel': 'poly'}, {'C': 1, 'kernel': 'rbf'}], 'split0_test_score': array([0.76953347, 0.47011454, 0.05254209, 0.76944514, 0.44256639,\n",
      "       0.38112765, 0.76939359, 0.44199058, 0.77625689]), 'split1_test_score': array([0.67137717, 0.26646633, 0.06233068, 0.67115696, 0.25896882,\n",
      "       0.41836638, 0.67112823, 0.25790618, 0.7674672 ]), 'split2_test_score': array([0.7690056 , 0.45315447, 0.05575884, 0.76900733, 0.42451306,\n",
      "       0.39678454, 0.76897566, 0.42388463, 0.79528721]), 'split3_test_score': array([0.74669076, 0.44982317, 0.05667725, 0.74664154, 0.42928998,\n",
      "       0.40104617, 0.74662197, 0.42871341, 0.77192134]), 'split4_test_score': array([0.7614994 , 0.54014293, 0.0578197 , 0.76146097, 0.53866153,\n",
      "       0.3847317 , 0.76146419, 0.53861118, 0.76123471]), 'mean_test_score': array([0.74362128, 0.43594029, 0.05702571, 0.74354239, 0.41879995,\n",
      "       0.39641129, 0.74351673, 0.41822119, 0.77443347]), 'std_test_score': array([0.03705149, 0.09081471, 0.00318127, 0.03712074, 0.09013358,\n",
      "       0.01321855, 0.03712039, 0.09044534, 0.01155206]), 'rank_test_score': array([2, 5, 9, 3, 6, 8, 4, 7, 1], dtype=int32)}\n",
      "      C  kernel     score\n",
      "0  0.01  linear  0.743621\n",
      "1  0.01    poly  0.435940\n",
      "2  0.01     rbf  0.057026\n",
      "3  0.10  linear  0.743542\n",
      "4  0.10    poly  0.418800\n",
      "5  0.10     rbf  0.396411\n",
      "6  1.00  linear  0.743517\n",
      "7  1.00    poly  0.418221\n",
      "8  1.00     rbf  0.774433\n"
     ]
    }
   ],
   "source": [
    "# create and train the support vector machine (Regressor)\n",
    "svr = SVR()\n",
    "parameters_svr = {'kernel':['linear', 'poly', 'rbf'], 'C':[0.01, 0.1, 1]}\n",
    "clf_svr = GridSearchCV(svr, parameters_svr)\n",
    "clf_svr.fit(x_train, y_train.reshape(-1))\n",
    "best_model_svr = clf_svr.best_estimator_\n",
    "print(best_model_svr)\n",
    "best_params_svr = clf_svr.best_params_\n",
    "print(best_params_svr) \n",
    "# prints out best_params as C=1, kernel=rbf\n",
    "best_score_svr = clf_svr.best_score_\n",
    "print(best_score_svr)\n",
    "# prints out best score as 0.7744334702078793\n",
    "print(clf_svr.score(x_test, y_test))\n",
    "print(clf_svr.cv_results_)\n",
    "hyperparameter_grid = pd.DataFrame(clf_svr.cv_results_['params'])\n",
    "grid_scores = pd.DataFrame(clf_svr.cv_results_['mean_test_score'], columns=['score'])\n",
    "df_svr_params_scores = pd.concat([hyperparameter_grid, grid_scores], axis = 1)\n",
    "print(df_svr_params_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(n_jobs=1)\n",
      "{'fit_intercept': True, 'n_jobs': 1}\n",
      "0.7530130357372388\n",
      "0.7632502357138924\n",
      "{'mean_fit_time': array([0.00030799, 0.00019178, 0.00017109, 0.00016618]), 'std_fit_time': array([1.72108848e-04, 4.41325606e-06, 2.37750070e-06, 6.64499569e-06]), 'mean_score_time': array([0.0001688 , 0.00015225, 0.00014615, 0.00014586]), 'std_score_time': array([3.17778965e-05, 2.27486810e-06, 1.55246931e-06, 5.81350351e-06]), 'param_fit_intercept': masked_array(data=[True, True, False, False],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value=True), 'param_n_jobs': masked_array(data=[1, -1, 1, -1],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value=999999), 'params': [{'fit_intercept': True, 'n_jobs': 1}, {'fit_intercept': True, 'n_jobs': -1}, {'fit_intercept': False, 'n_jobs': 1}, {'fit_intercept': False, 'n_jobs': -1}], 'split0_test_score': array([0.77776096, 0.77776096, 0.75880883, 0.75880883]), 'split1_test_score': array([0.69767877, 0.69767877, 0.65811186, 0.65811186]), 'split2_test_score': array([0.77744237, 0.77744237, 0.75465099, 0.75465099]), 'split3_test_score': array([0.75368371, 0.75368371, 0.73289938, 0.73289938]), 'split4_test_score': array([0.75849937, 0.75849937, 0.7426352 , 0.7426352 ]), 'mean_test_score': array([0.75301304, 0.75301304, 0.72942125, 0.72942125]), 'std_test_score': array([0.02933149, 0.02933149, 0.03680192, 0.03680192]), 'rank_test_score': array([1, 1, 3, 3], dtype=int32)}\n",
      "   fit_intercept  n_jobs     score\n",
      "0           True       1  0.753013\n",
      "1           True      -1  0.753013\n",
      "2          False       1  0.729421\n",
      "3          False      -1  0.729421\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Linear Regression Model\n",
    "lr = LinearRegression()\n",
    "parameters_lr = {'fit_intercept': [True, False], 'n_jobs':[1,-1]}\n",
    "clf_lr = GridSearchCV(lr, parameters_lr)\n",
    "clf_lr = GridSearchCV(lr, parameters_lr)\n",
    "clf_lr.fit(x_train, y_train)\n",
    "best_model_lr = clf_lr.best_estimator_\n",
    "print(best_model_lr)\n",
    "best_params_lr = clf_lr.best_params_\n",
    "print(best_params_lr) \n",
    "# prints out best_params as C=1, kernel=rbf\n",
    "best_score_lr = clf_lr.best_score_\n",
    "print(best_score_lr)\n",
    "# prints out best score as 0.7744334702078793\n",
    "print(clf_lr.score(x_test, y_test))\n",
    "print(clf_lr.cv_results_)\n",
    "hyperparameter_grid = pd.DataFrame(clf_lr.cv_results_['params'])\n",
    "grid_scores = pd.DataFrame(clf_lr.cv_results_['mean_test_score'], columns=['score'])\n",
    "df_lr_params_scores = pd.concat([hyperparameter_grid, grid_scores], axis = 1)\n",
    "print(df_lr_params_scores)\n",
    "\n",
    "# note to self, hyperparameter tuning for linear regression is not as useful as for support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_forecast =np.array(df.drop(['Prediction'], axis=1))[-future_day:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[295.69288574]\n",
      " [296.15887031]\n",
      " [292.55437035]\n",
      " [296.55447333]\n",
      " [292.82692024]\n",
      " [286.09266553]\n",
      " [278.00455676]\n",
      " [276.38691344]\n",
      " [282.2332178 ]\n",
      " [280.21118387]\n",
      " [286.04870065]\n",
      " [279.46391574]\n",
      " [278.3649825 ]\n",
      " [282.54973257]\n",
      " [289.34550038]\n",
      " [286.80478333]\n",
      " [287.499299  ]\n",
      " [287.93007932]\n",
      " [291.24445422]\n",
      " [290.38289357]\n",
      " [289.94332567]\n",
      " [289.25757062]\n",
      " [297.7589115 ]\n",
      " [292.57197247]\n",
      " [295.56107197]\n",
      " [301.41611001]\n",
      " [291.38510948]\n",
      " [293.3544179 ]\n",
      " [295.5698326 ]\n",
      " [290.82246148]\n",
      " [287.35861678]\n",
      " [290.3037514 ]\n",
      " [291.84225255]\n",
      " [290.19824648]\n",
      " [289.1257299 ]\n",
      " [294.5940064 ]\n",
      " [291.29720668]\n",
      " [297.1083607 ]\n",
      " [291.93899685]\n",
      " [296.01821505]\n",
      " [295.32369937]\n",
      " [304.67775939]\n",
      " [307.25365374]\n",
      " [310.31305391]\n",
      " [315.57034752]\n",
      " [312.35268997]\n",
      " [304.0272086 ]\n",
      " [309.70644104]\n",
      " [312.21198079]\n",
      " [306.03164041]\n",
      " [302.37438799]\n",
      " [298.71713557]\n",
      " [303.42938331]\n",
      " [302.14585688]\n",
      " [290.69938139]\n",
      " [280.87052225]\n",
      " [288.23780651]\n",
      " [293.45113524]\n",
      " [292.229068  ]\n",
      " [301.53040251]\n",
      " [300.66886883]\n",
      " [303.94809338]\n",
      " [305.00303479]\n",
      " [307.65807131]\n",
      " [308.50202983]\n",
      " [309.17894338]\n",
      " [316.40554541]\n",
      " [316.77475873]\n",
      " [323.03426825]\n",
      " [319.8693362 ]\n",
      " [321.1704917 ]\n",
      " [321.91775984]\n",
      " [326.2519258 ]\n",
      " [323.62330595]\n",
      " [327.58823164]\n",
      " [324.72226615]\n",
      " [321.61887415]\n",
      " [325.39036516]\n",
      " [319.42103462]\n",
      " [314.98133677]\n",
      " [312.93294009]\n",
      " [308.71303967]\n",
      " [307.19214065]\n",
      " [306.4536601 ]\n",
      " [314.48898945]\n",
      " [319.90454045]\n",
      " [313.3373307 ]\n",
      " [321.19688141]\n",
      " [321.65402448]\n",
      " [320.27378072]\n",
      " [321.81228187]\n",
      " [330.33995854]\n",
      " [335.38624231]\n",
      " [334.43675191]\n",
      " [338.66543991]\n",
      " [338.05006641]\n",
      " [339.31599071]\n",
      " [341.95345205]\n",
      " [342.38425933]\n",
      " [338.5511474 ]]\n",
      "[279.1083529  278.86086655 280.61187298 278.64600037 280.49288781\n",
      " 282.74315332 283.39479824 283.23969416 283.34601616 283.45062006\n",
      " 282.75293428 283.4517205  283.41615155 283.31632987 281.83933016\n",
      " 282.57556439 282.3956113  282.27587942 281.15197127 281.47805161\n",
      " 281.63535014 281.86835795 277.96540409 280.60425666 279.17724987\n",
      " 275.66686673 281.09652251 280.25623284 279.17268608 281.31460977\n",
      " 282.43337097 281.50682744 280.91205817 281.54487846 281.91141146\n",
      " 279.66755262 281.13124772 278.33791129 280.87219084 278.93621114\n",
      " 279.30007763 273.34657004 271.35330972 268.82280814 264.12715563\n",
      " 267.04853557 273.82828254 269.33758277 267.17299467 272.31555814\n",
      " 275.01024021 277.39618585 274.26284657 275.16878538 281.36099015\n",
      " 283.43275359 282.18657395 280.21193678 280.75092867 275.58968894\n",
      " 276.16371664 273.88624191 273.10233458 271.0285175  270.34092957\n",
      " 269.78014147 263.34721186 262.99984713 256.91103973 260.03239739\n",
      " 258.75837738 258.02065924 253.6723779  256.32237641 252.31357377\n",
      " 255.21872392 258.31622402 254.54467191 260.46800949 264.67213419\n",
      " 266.53222889 270.16699183 271.40243985 271.9865597  265.12432256\n",
      " 259.99811437 266.16954392 258.73239674 258.28149818 259.63789259\n",
      " 258.12503954 249.4992567  244.31842357 245.29259467 240.96649812\n",
      " 241.59355077 240.30484511 237.63797514 237.20508825 241.08287658]\n"
     ]
    }
   ],
   "source": [
    "# print prediction for next x days\n",
    "lr_predict = clf_lr.predict(x_forecast)\n",
    "print(lr_predict) \n",
    "svr_predict = clf_svr.predict(x_forecast)\n",
    "print(svr_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnote to self: support vector regression is better(more accurate) than linear regression when it comes to capturing non-linear relationships. (using kernel=rbf for svr)\\nsvr handle outliers better, more flexible(control hyperparameters), '\\nlinear regression is better when it comes to handling linear relationships, computationally less expensive, it is faster, easy to understand'\\n\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "note to self: support vector regression is better(more accurate) than linear regression when it comes to capturing non-linear relationships. (using kernel=rbf for svr)\n",
    "svr handle outliers better, more flexible(control hyperparameters), '\n",
    "linear regression is better when it comes to handling linear relationships, computationally less expensive, it is faster, easy to understand'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
